---
title: about image sensor
date: '2018-06-05T09:00:03+09:00'
tags:
  - cmos
  - sensor
photos:
  - >-
    https://japan.cnet.com/storage/2015/06/26/e56a6ed941433c516d4bab8995edf18a/150626_sony_alpha_05.jpg
---
一口にイメージセンサーと言っても、調べていくと非常に奥深いということがわかる。単純に「○○万画素のセンサー」と書いてるだけで、その特徴を表現できる訳ではないということですね。

少しそのあたりをまとめておこうと思う。
<!-- more -->

## フォトダイオード
これが最小単位。フォトダイオードは半導体素子で、光の強さに応じて電流が流れる素子である。何を材料に使うかで検出できる周波数が異なるのだが、シリコン(Si)であれば可視光(波長350〜750nm)をカバーできる。
ちなみに、シリコンはもっと広範囲の周波数の光を検出できるので、紫外光や赤外光も実は捉えることができる。実際にはカラーフィルターがあるので色は制限されているのだが・・・

## イメージを捉える
ひとつのフォトダイオードがいわばスペック上の1ピクセルになる。なので、横に6,000個、縦に4,000個フォトダイオードを並べれば2,400万画素のイメージができるということになる。でもちょっと待ってほしい。フォトダイオードは光の強さを電流として検知すると言ったが、色まではわからない。いったいどうやってフルカラーのイメージを生成しているのだろうか。

### 色を作る
可視光は光の三原色RGBの組み合わせでできているというのはご存知だと思う。ということは、フォトダイオードの上にRGBいずれかのフィルターを置くことで、特定の色の強さを検出できるということになる。なので、RGBRGBと順番にフォトダイオードに割り当てればフルカラーの画像が生成できるような気がする。

ところが、デジカメのカタログを見てみると例えば「2,400万画素のセンサー」などと書いている。あれ？RGBあるからセンサーはRGB各色あるの？フォトダイオードは7,200万あるの？疑問は尽きない。

### ベイヤーフィルター
先ほどの疑問の答えは「RGBそれぞれの画素を合計すると2,400万画素ある」である。ディスプレイ上の1ピクセルは複数のRGBの信号から補間されてできているということになる。ちなみにこの2,400万のRGBいずれかの信号の強さを集めたものを「RAWデータ」というんですね。

詳細についてはWikipediaの「[ベイヤーフィルター](https://ja.wikipedia.org/wiki/%E3%83%99%E3%82%A4%E3%83%A4%E3%83%BC%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%83%BC)」を参照してもらいたいのだが、2x2のピクセルにRGBを割り当てる。このとき、Gが2ピクセル存在するんだがこれは人間の目が緑の変化に敏感だからという理由らしい。というわけでイメージセンサーは半分緑ってことになりますね。画像処理エンジンはこのデータを処理して実際の画像を生成しているんですね。

Wikipediaや、[THE BAYER SENSOR STRATEGY](http://www.red.com/learn/red-101/bayer-sensor-strategy)というサイトに、処理前のデータがよくわかる画像があります。
![ベイヤーフィルター](https://c.imagesensor.club/2018/06/05/bayer-filter.png)

我々が実際に見ている映像とはだいぶ違いますね。




